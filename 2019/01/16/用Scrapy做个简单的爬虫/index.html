<!DOCTYPE html>
<html lang="zh-cmn-Hans" prefix="og: http://ogp.me/ns#" class="han-init">
<head>
  <meta charset="utf-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

  <link rel="icon" href="/git-favicon.ico">
  
  <title>一手代码一手菜谱 | 用Scrapy做个简单的爬虫</title>
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="/lib/fancybox/jquery.fancybox-1.3.4.css">
  <!--在这里倒入jquery 方便处理部分页面的jquery-->
  <script src="https://cdn.staticfile.org/jquery/1.7/jquery.min.js" type="text/javascript" ></script>
</head>

<body>
	<header class="site-header navfixed-false">
  <div class="container">
      <h1><a href="/" title="一手代码一手菜谱"><span class="octicon octicon-mark-github"></span> 一手代码一手菜谱</a></h1>
      <nav class="site-header-nav" role="navigation">
        
              
              <a href="/"  class=" site-header-nav-item hvr-underline-from-center" title="首页">首页</a>
        
              
              <a href="/category/" target="true" class=" site-header-nav-item hvr-underline-from-center" title="分类">分类</a>
        
              
              <a href="/message/"  class=" site-header-nav-item hvr-underline-from-center" title="留言板">留言板</a>
        
      </nav>
  </div>
</header>

	
<section class="collection-head geopattern" data-pattern-id="用Scrapy做个简单的爬虫" >
    <div class="container">
        <div class="collection-title">
            <h1 class="collection-header">
                用Scrapy做个简单的爬虫
            </h1>
            
                <div class="collection-info">
                    <span class="meta-info">
                        <span class="octicon octicon-calendar"></span>
                        <time datetime="2019-01-15T18:59:24.000Z" itemprop="datePublished">2019-01-16</time>
                    </span>
                    
                </div>
            
        </div>
    </div>
</section>
	<section class="container">
    <div class="columns">
        <div class="column  three-fourths ">
            <article class="article-content markdown-body">
                <h3 id="Scrapy文档"><a href="#Scrapy文档" class="headerlink" title="Scrapy文档"></a>Scrapy文档</h3><p>官网<br><a href="https://scrapy.org/" target="_blank" rel="external">https://scrapy.org/</a></p>
<p>英文文档 <em>（版本较新）</em><br><a href="https://doc.scrapy.org/en/latest/" target="_blank" rel="external">https://doc.scrapy.org/en/latest/</a></p>
<p>中文文档 <em>（版本比英文版滞后）</em><br><a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/index.html" target="_blank" rel="external">https://scrapy-chs.readthedocs.io/zh_CN/0.24/index.html</a></p>
<h3 id="我的环境："><a href="#我的环境：" class="headerlink" title="我的环境："></a>我的环境：</h3><ul>
<li>python 3.6</li>
<li>scrapy 1.5.1</li>
</ul>
<h3 id="安装Scrapy"><a href="#安装Scrapy" class="headerlink" title="安装Scrapy"></a>安装Scrapy</h3><pre><code class="bash">$ pip3 install Scrapy
</code></pre>
<h3 id="创建Scrapy项目"><a href="#创建Scrapy项目" class="headerlink" title="创建Scrapy项目"></a>创建Scrapy项目</h3><pre><code class="bash">$ scrapy startproject novel
</code></pre>
<p><strong>将会生成如下项目结构目录</strong></p>
<pre><code class="angular2html">novel/
    scrapy.cfg
    novel/
        __init__.py
        items.py
        pipelines.py
        settings.py
        spiders/
            __init__.py
            ...
</code></pre>
<a id="more"></a>
<p><strong>这些文件分别是:</strong></p>
<ul>
<li><code>scrapy.cfg</code>: 项目的配置文件</li>
<li><code>novel/</code>: 该项目的python模块。之后您将在此加入代码。</li>
<li><code>novel/items.py</code>: 项目中的item文件.</li>
<li><code>novel/pipelines.py</code>: 项目中的pipelines文件.</li>
<li><code>novel/settings.py</code>: 项目的设置文件.</li>
<li><code>novel/spiders/</code>: 放置spider代码的目录.</li>
</ul>
<p>以<a href="https://www.readnovel.com/free/all?pageSize=50&amp;pageNum=1" target="_blank" rel="external">小说阅读网</a>为例，爬取一些免费的小说信息<br><img src="/2019/01/16/用Scrapy做个简单的爬虫/1.png" alt="爬虫目标页面"></p>
<p><strong>创建一个爬虫(爬虫名称可以自己取)</strong></p>
<pre><code class="bash"># scrapy genspider [爬虫名称] [域名]
$ scrapy genspider readnovel readnovel.com
</code></pre>
<p><code>novel/spiders/readnovel</code>就是创建的爬虫文件</p>
<ul>
<li><code>name</code>: 用于区别Spider，该名字必须是唯一的</li>
<li><code>start_urls</code>: 在启动时进行爬取的url列表</li>
<li><code>parse()</code>: 是spider的一个方法。 被调用时，每个初始URL完成下载后生成的 <code>Response</code> 对象将会作为唯一的参数传递给该函数</li>
</ul>
<p><strong>编写爬虫代码</strong></p>
<pre><code class="python"># coding:utf-8
import scrapy
import math
from urllib import parse

class ReadnovelSpider(scrapy.Spider):
    # 爬虫名称
    name = &quot;readnovel&quot;
    # 允许抓取的域名地址
    allow_url = [&#39;readnovel.com&#39;]
    # 目标链接
    start_urls = [&#39;https://www.readnovel.com/free/all?pageSize=50&amp;pageNum=1&#39;]

    def parse(self, response):

        # 获取列表信息
        bookList = response.xpath(&#39;//div[@class=&quot;right-book-list&quot;]/ul/li&#39;)
        for book in bookList:
            item = {}   # 小说数据

            # 书名
            item[&#39;bookName&#39;] = book.xpath(&#39;.//div[@class=&quot;book-info&quot;]/h3/a/text()&#39;).extract_first()
            # 作者
            item[&#39;author&#39;] = book.xpath(&#39;.//div[@class=&quot;book-info&quot;]/h4/a[@class=&quot;default&quot;]/text()&#39;).extract_first()
            # 小说图片
            item[&#39;picture&#39;] = book.xpath(&#39;.//div[@class=&quot;book-img&quot;]/a/img/@src&#39;).extract_first()
            # 小说介绍
            item[&#39;intro&#39;] = book.xpath(&#39;.//div[@class=&quot;book-info&quot;]/p[@class=&quot;intro&quot;]/text()&#39;).extract_first()

            yield item

        # 记录当前页码
        urlParams = parse.parse_qs(parse.urlparse(response.url).query)
        currentPageNum = int(urlParams[&#39;pageNum&#39;][0])

        # 获取翻页DOM
        pages = response.xpath(&#39;//div[@id=&quot;page-container&quot;]&#39;)
        for page in pages:         
            # 数据总数          
            dataTotal = int(page.xpath(&#39;./@data-total&#39;).extract_first())
            # 每页返回数据数量
            pageSize = int(page.xpath(&#39;./@data-size&#39;).extract_first())
            # 计算数据页数
            pageCount = math.ceil(dataTotal / pageSize)

            if currentPageNum &lt;= pageCount:
                # 添加下一页链接
                nextURL = &#39;https://www.readnovel.com/free/all?pageSize=5&amp;pageNum={}&#39;.format(currentPageNum + 1)
                print(&#39;next url:&#39;, nextURL)
                yield response.follow(nextURL, callback=self.parse)
</code></pre>
<p>在项目目录下运行命令</p>
<pre><code class="bash">$ scrapy crawl readnovel -o rst.json
</code></pre>
<p><em>Scrapy会把结果保存到<code>novel/rst.json</code></em></p>
<p><strong>内容如图</strong><br><img src="/2019/01/16/用Scrapy做个简单的爬虫/16.50.19.png" alt="http://qiweihan.com"></p>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>实际应用中不太会将爬取的数据全部以文件形式保存，一般会保存到数据库中，方便后续的数据处理</p>
<p>大量爬取一个网站的时候可能会被网站屏蔽访问，所以需要对<code>user-agent</code>、<code>ip</code>等信息进行伪装</p>

            </article>
            
            <div class="share">
                <!--开启分享-->
<div class="share-component" data-disabled="google,twitter,facebook" data-description="Scrapy文档官网https://scrapy.or..."></div>

<script src="/js/share.min.js"></script>

            </div>
            

            

            

            
            <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src='//unpkg.com/valine/dist/Valine.min.js'></script>

<div id="vcomments"></div>

<script>
    new Valine({
        el: '#vcomments',
        appId: '2PGbHYNPvCLhCXClDIGFKp76-gzGzoHsz',
        appKey: 'h9cj9PlNWJOHuLttqVd93glp',
        avatar: 'undefined',
        placeholder: '留言说点什么吧',
        pageSize: '15',
        meta: ['nick', 'mail'],
        visitor: true,
    })
</script>


            

            

            
        </div>
        <div class="column one-fourth">
            
            
            


<h3>Post Directory</h3>

<div id="post-directory-module">
	<section class="post-directory">
		<p><strong class="toc-title">文章目录</strong></p>
		<ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Scrapy文档"><span class="toc-text">Scrapy文档</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#我的环境："><span class="toc-text">我的环境：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#安装Scrapy"><span class="toc-text">安装Scrapy</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#创建Scrapy项目"><span class="toc-text">创建Scrapy项目</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#其他"><span class="toc-text">其他</span></a></li></ol>
	</section>
</div>
            
        </div>
    </div>
</section>


<footer class="container">
    <div class="site-footer" role="contentinfo">
        <div class="copyright left mobile-block">
                © 2016
                <span title="yumemor">yumemor</span>
                <a href="javascript:window.scrollTo(0,0)" class="right mobile-visible">TOP</a>
        </div>

        <ul class="site-footer-links right mobile-hidden">
            <li>
                <a href="javascript:window.scrollTo(0,0)" >TOP</a>
            </li>
        </ul>

        <a href="https://github.com/yumemor/hexo-theme-primer" target="_blank" aria-label="view source code">
            <span class="mega-octicon octicon-mark-github" title="GitHub"></span>
        </a>

        <ul class="site-footer-links mobile-hidden">
            
                  
                  <li>
                    <a href="/"  title="首页">首页</a>
                  </li>
            
                  
                  <li>
                    <a href="/category/" target="true" title="分类">分类</a>
                  </li>
            
                  
                  <li>
                    <a href="/message/"  title="留言板">留言板</a>
                  </li>
            
            <li>
                <a href="/atom.xml">
                    <span class="octicon octicon-rss" style="color:orange;"></span>
                </a>
            </li>
        </ul>
    </div>
</footer>

		<script src="/js/geopattern.js"></script>
		<script src="/js/highlight.pack.js"></script>
		<script src="/lib/fancybox/jquery.fancybox-1.3.4.pack.js"></script>

		
			<script src="/js/toc.js"></script>
		

		<script src="/js/index.js"></script>

		 <script src="/js/popular_repo.js"></script> 

	</body>
</html>